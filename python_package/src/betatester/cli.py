import asyncio
import json
import logging
import os
from typing import Annotated, Optional

import typer
from betatester.execution import ScrapeExecutor
from rich import print

from .betatester_types import (
    FileClient,
    FileClientType,
    ScrapeFiles,
    ScrapeVariables,
)

app = typer.Typer(no_args_is_help=True)


def _create_file_client(file_client: Optional[FileClientType]) -> FileClient:
    file_client_config = os.getenv("FILE_CLIENT_CONFIG")
    if file_client_config is None:
        raise ValueError(
            "FILE_CLIENT_CONFIG environment variable not set, cannot use file client"
        )

    if file_client == FileClientType.local:
        from betatester.file.local import LocalFileClient

        config = json.loads(file_client_config)
        save_path = config.get("save_path")

        if save_path is None:
            raise ValueError(
                "save_path not in FILE_CLIENT_CONFIG, cannot use local file client"
            )

        return LocalFileClient(save_path)
    else:
        raise ValueError(f"Invalid file provider: {file_client}")


@app.command("start", no_args_is_help=True)
def start(
    url: Annotated[str, typer.Option(help="URL to test")],
    high_level_goal: Annotated[
        str,
        typer.Option(help="High level goal to accomplish at url"),
    ],
    max_page_views: Annotated[
        Optional[int],
        typer.Option(help="Max page views to take across the entire test"),
    ] = 10,
    max_total_actions: Annotated[
        Optional[int],
        typer.Option(help="Max total actions to take across the entire test"),
    ] = 20,
    max_action_attempts_per_step: Annotated[
        Optional[int],
        typer.Option(help="Max actions to take on a single page"),
    ] = 5,
    viewport_width: Annotated[
        int, typer.Option(help="Viewport width in pixels")
    ] = 1280,
    viewport_height: Annotated[
        int, typer.Option(help="Viewport height in pixels")
    ] = 720,
    variables: Annotated[
        Optional[str],
        typer.Option(
            help="A json encoded string, variables to be used by the bot in the test in the form of {<variable_name>: <variable_value>}",
        ),
    ] = None,
    files: Annotated[
        Optional[str],
        typer.Option(
            help="A json encoded string, files to be used by the bot in the test in the form of {<file_key>: {'name': <file_name>, 'mimeType': <file_mimeType>, 'b64_content': <file_b64_encoded_string>} }",
        ),
    ] = None,
    file_client_type: Annotated[
        Optional[FileClientType],
        typer.Option(
            help="Provide a file client if you want to persist files generated by the test, if you do provide a client, make sure to provide the relevant credentials in the FILE_CLIENT_CONFIG environment variable",
        ),
    ] = None,
    save_playwright_trace: Annotated[
        bool,
        typer.Option(
            help="Save Playwright trace, must provide a file client to use. See https://playwright.dev/python/docs/trace-viewer-intro for more information",
        ),
    ] = False,
    view_browser: Annotated[
        bool,
        typer.Option(
            help="Opens up the browser in headful mode to view the test in action",
        ),
    ] = False,
):
    # setup logging
    logging.basicConfig(
        format="%(asctime)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    logger = logging.getLogger("betatester")
    logger.setLevel(
        level=logging.INFO,
    )

    openai_api_key = os.getenv("OPENAI_API_KEY")
    if openai_api_key is None:
        raise ValueError("OPENAI_API_KEY environment variable not set")

    if variables is None:
        variables_loaded = None
    else:
        variables_loaded = ScrapeVariables(**json.loads(variables))  # type: ignore

    if files is None:
        files_loaded = None
    else:
        files_loaded = ScrapeFiles(**json.loads(files))

    if file_client_type is None:
        file_client = None
    else:
        file_client = _create_file_client(file_client_type)

    scraper = ScrapeExecutor(
        url=url,
        high_level_goal=high_level_goal,
        max_page_views=max_page_views,
        max_total_actions=max_total_actions,
        max_action_attempts_per_step=max_action_attempts_per_step,
        viewport_width=viewport_width,
        viewport_height=viewport_height,
        variables=variables_loaded,
        files=files_loaded,
        openai_api_key=openai_api_key,
        file_client=file_client,
        save_playwright_trace=save_playwright_trace,
        headless=not view_browser,
    )

    try:
        asyncio.run(scraper.run())
        print()
        print("Test [bold green]completed[/bold green] successfully!")
    except Exception as e:
        print()
        print(f"Test [bold red]failed[/bold red] with error: {e}")


if __name__ == "__main__":
    app()
